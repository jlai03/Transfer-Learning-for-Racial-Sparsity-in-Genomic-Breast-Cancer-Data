{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Libraries \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Data \n",
    "Checkpoint: Load cached data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>sample_data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>[[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>Metaplastic carcinoma, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>[[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>Metaplastic carcinoma, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>white</td>\n",
       "      <td>[[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>Infiltrating duct carcinoma, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>[[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>Infiltrating duct carcinoma, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white</td>\n",
       "      <td>[[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>Infiltrating duct carcinoma, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>not reported</td>\n",
       "      <td>[[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>Infiltrating duct carcinoma, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>not reported</td>\n",
       "      <td>[[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>Infiltrating duct carcinoma, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>black or african american</td>\n",
       "      <td>[[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>Infiltrating duct carcinoma, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>black or african american</td>\n",
       "      <td>[[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>Infiltrating duct carcinoma, NOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>white</td>\n",
       "      <td>[[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...</td>\n",
       "      <td>Infiltrating duct carcinoma, NOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           race  \\\n",
       "0                         white   \n",
       "1                         white   \n",
       "2                         white   \n",
       "3                         white   \n",
       "4                         white   \n",
       "...                         ...   \n",
       "1495               not reported   \n",
       "1496               not reported   \n",
       "1497  black or african american   \n",
       "1498  black or african american   \n",
       "1499                      white   \n",
       "\n",
       "                                            sample_data  \\\n",
       "0     [[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...   \n",
       "1     [[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...   \n",
       "2     [[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...   \n",
       "3     [[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...   \n",
       "4     [[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...   \n",
       "...                                                 ...   \n",
       "1495  [[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...   \n",
       "1496  [[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...   \n",
       "1497  [[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...   \n",
       "1498  [[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...   \n",
       "1499  [[0.0, 0.0010240421486530794, 1.0, 0.0, 0.0, 0...   \n",
       "\n",
       "                                 label  \n",
       "0           Metaplastic carcinoma, NOS  \n",
       "1           Metaplastic carcinoma, NOS  \n",
       "2     Infiltrating duct carcinoma, NOS  \n",
       "3     Infiltrating duct carcinoma, NOS  \n",
       "4     Infiltrating duct carcinoma, NOS  \n",
       "...                                ...  \n",
       "1495  Infiltrating duct carcinoma, NOS  \n",
       "1496  Infiltrating duct carcinoma, NOS  \n",
       "1497  Infiltrating duct carcinoma, NOS  \n",
       "1498  Infiltrating duct carcinoma, NOS  \n",
       "1499  Infiltrating duct carcinoma, NOS  \n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Loading Data\n",
    "model_data_df = pickle.load(open('data/model_data.pkl', 'rb'))\n",
    "model_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODE DATA\n",
    "encoded_labels = pd.get_dummies(model_data_df.label)\n",
    "encoded_df = model_data_df.join(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Data Frames by Race \n",
    "white_df = encoded_df[encoded_df[\"race\"] == \"white\"]\n",
    "black_df = encoded_df[encoded_df[\"race\"] == \"black or african american\"]\n",
    "asian_df = encoded_df[encoded_df[\"race\"] == \"asian\"]\n",
    "prognosis_names = encoded_df.label.unique()\n",
    "\n",
    "# Train Test Split\n",
    "def df_split(df): \n",
    "    split_index = int(0.7 * len(df)) \n",
    "    return df.iloc[:split_index], df.iloc[split_index:]\n",
    "\n",
    "train_white_df, test_white_df = df_split(white_df) \n",
    "train_black_df, test_black_df = df_split(black_df) \n",
    "train_asian_df, test_asian_df = df_split(asian_df)\n",
    "\n",
    "# Concatenate Final Sets \n",
    "train_df = pd.concat([train_white_df, train_black_df, train_asian_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results for (train mixed, test black / asian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Model Data --> [takes 1 min. 15 sec.]\n",
    "def get_x_y(df, prognosis_names): \n",
    "    x = np.stack(df.sample_data.values)\n",
    "    y = df.filter(prognosis_names).values\n",
    "    return x, y\n",
    "\n",
    "def train_val_split(data):\n",
    "    # returns: x_train, x_val, y_train, y_val\n",
    "    x, y = data\n",
    "    return train_test_split(x, y, test_size=0.15, random_state=42)\n",
    "\n",
    "\n",
    "##### Main Code #########\n",
    "x_train, x_val, y_train, y_val = train_val_split(get_x_y(train_df, prognosis_names)) # training data\n",
    "\n",
    "x_test_white, y_test_white = get_x_y(test_black_df, prognosis_names)\n",
    "x_test_black, y_test_black = get_x_y(test_black_df, prognosis_names)\n",
    "x_test_asian, y_test_asian = get_x_y(test_asian_df, prognosis_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 41s 1s/step - loss: 125.0574 - accuracy: 0.4747 - val_loss: 61.5682 - val_accuracy: 0.6993\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 38s 1s/step - loss: 59.2514 - accuracy: 0.5204 - val_loss: 54.3444 - val_accuracy: 0.6993\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 43s 2s/step - loss: 40.4722 - accuracy: 0.5933 - val_loss: 26.8635 - val_accuracy: 0.6923\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 42s 2s/step - loss: 23.0151 - accuracy: 0.6489 - val_loss: 16.3254 - val_accuracy: 0.7063\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 37s 1s/step - loss: 19.3822 - accuracy: 0.6069 - val_loss: 14.3102 - val_accuracy: 0.6993\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 41s 2s/step - loss: 14.4028 - accuracy: 0.5946 - val_loss: 11.9538 - val_accuracy: 0.6503\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 39s 1s/step - loss: 12.6150 - accuracy: 0.5773 - val_loss: 14.6824 - val_accuracy: 0.7063\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 42s 2s/step - loss: 10.1073 - accuracy: 0.6638 - val_loss: 8.0021 - val_accuracy: 0.6573\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 41s 2s/step - loss: 7.2268 - accuracy: 0.6601 - val_loss: 6.2413 - val_accuracy: 0.7133\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 39s 1s/step - loss: 6.4802 - accuracy: 0.6527 - val_loss: 5.7812 - val_accuracy: 0.5035\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 38s 1s/step - loss: 5.2883 - accuracy: 0.6836 - val_loss: 4.7077 - val_accuracy: 0.7343\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 46s 2s/step - loss: 4.4051 - accuracy: 0.7392 - val_loss: 5.3461 - val_accuracy: 0.4266\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 44s 2s/step - loss: 4.7416 - accuracy: 0.6316 - val_loss: 4.2418 - val_accuracy: 0.7273\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 41s 2s/step - loss: 5.2342 - accuracy: 0.6316 - val_loss: 7.2959 - val_accuracy: 0.4965\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 41s 2s/step - loss: 5.6573 - accuracy: 0.5822 - val_loss: 4.8042 - val_accuracy: 0.6084\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 40s 2s/step - loss: 4.2120 - accuracy: 0.6972 - val_loss: 3.8784 - val_accuracy: 0.7413\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 40s 2s/step - loss: 3.7914 - accuracy: 0.7355 - val_loss: 3.7361 - val_accuracy: 0.7203\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 40s 2s/step - loss: 3.7069 - accuracy: 0.7268 - val_loss: 3.6995 - val_accuracy: 0.7762\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 42s 2s/step - loss: 3.6775 - accuracy: 0.7219 - val_loss: 4.1552 - val_accuracy: 0.4895\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 37s 1s/step - loss: 3.5633 - accuracy: 0.7108 - val_loss: 4.0472 - val_accuracy: 0.6993\n"
     ]
    }
   ],
   "source": [
    "# TRAIN NEURAL NETWORK\n",
    "num_classes = model_data_df.label.nunique()\n",
    "\n",
    "# Basic DNN Model \n",
    "reg_rate = 0.1\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(60623, 26)),  # Flattening the input\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(reg_rate)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=regularizers.l2(reg_rate)),\n",
    "    Dense(num_classes, activation='softmax')  # Output layer with softmax for multi-class\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=32, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 69ms/step - loss: 3.6573 - accuracy: 0.8205\n",
      "Performance on White Patients\n",
      "----------------------------------\n",
      "Loss on test data: 3.6573004722595215\n",
      "Accuracy on test data: 0.8205128312110901\n"
     ]
    }
   ],
   "source": [
    "# Check Test Performance - White Patients\n",
    "evaluation = model.evaluate(x_test_white, y_test_white)\n",
    "\n",
    "# 'evaluation' will contain the loss value and accuracy\n",
    "loss = evaluation[0]\n",
    "accuracy = evaluation[1]\n",
    "\n",
    "print(\"Performance on White Patients\")\n",
    "print(\"----------------------------------\")\n",
    "print(f\"Loss on test data: {loss}\")\n",
    "print(f\"Accuracy on test data: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 71ms/step - loss: 3.6573 - accuracy: 0.8205\n",
      "Performance on Black Patients\n",
      "----------------------------------\n",
      "Loss on test data: 3.6573004722595215\n",
      "Accuracy on test data: 0.8205128312110901\n"
     ]
    }
   ],
   "source": [
    "# Check Test Performance - Black & AA Patients\n",
    "evaluation = model.evaluate(x_test_black, y_test_black)\n",
    "\n",
    "# 'evaluation' will contain the loss value and accuracy\n",
    "loss = evaluation[0]\n",
    "accuracy = evaluation[1]\n",
    "\n",
    "print(\"Performance on Black Patients\")\n",
    "print(\"----------------------------------\")\n",
    "print(f\"Loss on test data: {loss}\")\n",
    "print(f\"Accuracy on test data: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 244ms/step - loss: 3.1354 - accuracy: 0.8214\n",
      "Performance on Asian Patients\n",
      "----------------------------------\n",
      "Loss on test data: 3.1354243755340576\n",
      "Accuracy on test data: 0.8214285969734192\n"
     ]
    }
   ],
   "source": [
    "# Check Test Performance - Asian Patients\n",
    "evaluation = model.evaluate(x_test_asian, y_test_asian)\n",
    "\n",
    "# 'evaluation' will contain the loss value and accuracy\n",
    "loss = evaluation[0]\n",
    "accuracy = evaluation[1]\n",
    "\n",
    "print(\"Performance on Asian Patients\")\n",
    "print(\"----------------------------------\")\n",
    "print(f\"Loss on test data: {loss}\")\n",
    "print(f\"Accuracy on test data: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
